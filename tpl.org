#+TITLE: TPL Workshop
#+AUTHOR: Gabby Resch

#+ox-ipynb-keyword-metadata: key1 key2

* Introduction
This tutorial presents a few options for preparing 3D-printed visualizations from datasets available through the City of Toronto's [[https://portal0.cf.opendata.inter.sandbox-toronto.ca/][Open Data Portal]]. 
* Preparation
Most of the processes used are software/language agnostic, but I strongly recommend getting a baseline understanding of the modern Python data science ecosystem in order to fully appreciate the possibilities for multimodal data representation that it affords. That said, here are some initial pieces you'll want to get set up:  
- Make sure you have a working Python installation! Download Anaconda if you don't already have a Python installation (and follow its setup instructions): https://www.anaconda.com/download/
- You will need to install the following Python libraries: pandas, numpy, stat, matplotlib, seaborn, plotly. If you are using Anaconda, use conda install from a command line. Alternatively, use pip or easy install.
- There is a difference between Python 2 and 3. You might need to familiarize yourself with this, depending on which version you install. 
- Download and set up JupyterLab and/or Jupyter Notebook: https://anaconda.org/conda-forge/jupyterlab
- Download Blender if you don't have 3D modeling software (e.g. Maya): https://www.blender.org/download/
- Download QGIS if you want to create maps and other geospatial data representations: https://qgis.org/en/site/forusers/download.html
* Data Sources
We will be taking data from the City of Toronto's portal, but there are various other interesting datasets that you might consider working with: you can collect and use your own biometric/self-tracking data if you use a wearable device like a fitbit; kaggle provides lots of awesome datasets (the pokemon one is fun if you're working with kids): https://kaggle.com/datasets; google has a dataset search tool: https://toolbox.google.com/datasetsearch; 538 has plenty of interesting social and sports-related datasets: https://data.fivethirtyeight.com/; you might also scan the Open North community: https://github.com/opennorth.

That said, I would recommend starting with a simple dataset, or spending plenty of time familiarizing yourself with a dataset in a spreadsheet before moving to pandas dataframes (even though I have included some very basic cleaning functions in the notebook cells below). There are various tools you can use to clean/munge/prepare your data, including Excel, Libre Office Calc, R, etc. I prefer pandas, a Python library for data analysis. There are numerous excellent tutorials that detail how to import and prepare data (using pandas) in an iPython/Jupyter notebook. Your best bet is to do the free datacamp tutorials if you're completely new to this stuff: https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python

For this exercise, we will be working with pedestrian data from the King Street Pilot Project. All data was scraped from the .pdf reports that the city of Toronto has made available here: https://www.toronto.ca/city-government/planning-development/planning-studies-initiatives/king-street-pilot/data-reports-background-materials/
The data is available in the data directory of the repository that contains this file.  
* Working with Data in a Python/Jupyter Notebook

Import the necessary libraries:
#+BEGIN_SRC ipython 
import pandas as pd
import numpy as np
import stat as st
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.plotly as py
import plotly.graph_objs as go
#+END_SRC

Set the figure size for charts:
#+ipynb-newcell
#+BEGIN_SRC ipython
plt.rcParams['figure.figsize'] = [10, 8]
#+END_SRC

Import your data:
#+ipynb-newcell
#+BEGIN_SRC ipython
pvol = pd.read_csv('data/king_pedestrian_volume.csv')
#+END_SRC

Set the index for the pandas dataframe you've created:
#+ipynb-newcell
#+BEGIN_SRC ipython
pvol.set_index('street')
#+END_SRC
#+RESULTS:

Create some objects for each street. Normally, I wouldn't want such long names (and wide dataframes), but explaining the hows and whys of reshaping data takes too long. If you're interested, read Hadley Wickham's papers on the subject (http://vita.had.co.nz/papers/tidy-data.html) or follow these instructions for reshaping in pandas: https://pandas.pydata.org/pandas-docs/stable/reshaping.html
#+ipynb-newcell
#+BEGIN_SRC ipython
#### am objects
# bathurst
pvol_bathurst_am = pvol[['street',
                         'am_bathurst_baseline',
                         'am_bathurst_january',
                         'am_bathurst_february',
                         'am_bathurst_march',
                         'am_bathurst_april',
                         'am_bathurst_may',
                         'am_bathurst_june']]

# spadina
pvol_spadina_am = pvol[['street',
                        'am_spadina_baseline',
                        'am_spadina_january',
                        'am_spadina_february',
                        'am_spadina_march',
                        'am_spadina_april',
                        'am_spadina_may',
                        'am_spadina_june']]

# bay
pvol_bay_am = pvol[['street',
                    'am_bay_baseline',
                    'am_bay_january',
                    'am_bay_february',
                    'am_bay_march',
                    'am_bay_april',
                    'am_bay_may',
                    'am_bay_june']]

# jarvis
pvol_jarvis_am = pvol[['street',
                       'am_jarvis_baseline',
                       'am_jarvis_january',
                       'am_jarvis_february',
                       'am_jarvis_march',
                       'am_jarvis_april',
                       'am_jarvis_may',
                       'am_jarvis_june']]

#### pm objects
# bathurst
pvol_bathurst_pm = pvol[['street',
                         'pm_bathurst_baseline',
                         'pm_bathurst_january',
                         'pm_bathurst_february',
                         'pm_bathurst_march',
                         'pm_bathurst_april',
                         'pm_bathurst_may',
                         'pm_bathurst_june']]

# spadina
pvol_spadina_pm = pvol[['street',
                        'pm_spadina_baseline',
                        'pm_spadina_january',
                        'pm_spadina_february',
                        'pm_spadina_march',
                        'pm_spadina_april',
                        'pm_spadina_may',
                        'pm_spadina_june']]

# bay
pvol_bay_pm = pvol[['street',
                    'pm_bay_baseline',
                    'pm_bay_january',
                    'pm_bay_february',
                    'pm_bay_march',
                    'pm_bay_april',
                    'pm_bay_may',
                    'pm_bay_june']]

# jarvis
pvol_jarvis_pm = pvol[['street',
                       'pm_jarvis_baseline',
                       'pm_jarvis_january',
                       'pm_jarvis_february',
                       'pm_jarvis_march',
                       'pm_jarvis_april',
                       'pm_jarvis_may',
                       'pm_jarvis_june']]
#+END_SRC
#+RESULTS:

Using the standard pandas plotting functions (which rely on matplotlib), you can prepare bare-bones static charts (use matplotlib or seaborn if you want to customize):
#+ipynb-newcell
#+BEGIN_SRC ipython
pvol_bathurst_am.plot.bar(x='street', 
                          rot=0,
                          width=0.85, 
                          title='AM Peak Pedestrian Volume Measured at Bathurst');
#+END_SRC
#+RESULTS:

If you want horizontal charts, you can chain barh to the plot method:
#+ipynb-newcell
#+BEGIN_SRC ipython
pvol_bathurst_am.plot.barh(x='street', 
                           rot=0,
                           width=0.85,
                           title='AM Peak Pedestrian Volume Measured at Bathurst')
plt.gca().invert_yaxis();
#+END_SRC
#+RESULTS:

There are lots of ways to adjust the colours if you want, but I like my charts to look like life savers ;-)

Far more interesting, though, is the potential for creating interactive charts inside a notebook. There are lots of libraries you can use (such as Bokeh or Pygal), but I find Plotly to be the most well-developed. It also has an easy-to-use web portal. What we're going to do is create a grouped bar chart using the Plotly python library.
#+ipynb-newcell
#+BEGIN_SRC ipython
#### plotly-based grouped bar charts
# AM Bathurst
baseline = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_baseline'],
    name='AM Bathurst Baseline',
    hoverinfo='y+name'
)
january = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_january'],
    name='AM Bathurst January',
    hoverinfo='y+name'
)
february = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_february'],
    name='AM Bathurst February',
    hoverinfo='y+name'
)
march = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_march'],
    name='AM Bathurst March',
    hoverinfo='y+name'
)
april = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_april'],
    name='AM Bathurst April',
    hoverinfo='y+name'
)
may = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_may'],
    name='AM Bathurst May',
    hoverinfo='y+name'
)
june = go.Bar(
    x=pvol['street'],
    y=pvol['am_bathurst_june'],
    name='AM Bathurst June',
    hoverinfo='y+name'
)

data = [baseline, january, february, march, april, may, june]
layout = go.Layout(
    barmode='group',
    # bargap=0.15,
    bargroupgap=0.1,
    hovermode='closest'
    # showlegend=False
)

fig = go.Figure(data=data, layout=layout)
py.iplot(fig, filename='grouped-bar')
#+END_SRC
#+RESULTS:

The dataframe provides data for the 7-10 am and 4-7 pm peak periods at the intersections Bathurst, Spadina, Bay, and Jarvis at both King and Queen. Change your arguments accordingly to prepare different charts.
* 3D Bars in Blender
Now, let's take the same charts we prepared for the screen and render them as 3D models. This section assumes that you have the csv and bpy modules loaded in your Python ecosystem. Depending on your operating system and Python configuration, they may be pre-loaded, or you may need to install and configure separately.

- open king_pedestrian_volume.csv in a spreadsheet application (calc or excel) and copy the entire row for king
- open a new window/file and paste special with the transpose option to turn your row of data into a column
- remove the "king" row at the top, then save as pvol_king.csv
- repeat these steps for queen
- in Blender, open up a text editor window

#+ipynb-newcell
#+BEGIN_SRC ipython
%%html
<img src="images/blender.gif"> 
#+END_SRC
#+RESULTS:

- use the 3Dbars.py script and make sure to import pvol_king.csv and pvol_queen.csv separately
- export entire block or separate streets as .obj or .stl files
* Preparing 3D Data Maps
We are going to work with data from the [[https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#8c732154-5012-9afe-d0cd-ba3ffc813d5a][2016 Neighbourhood Profiles Dataset]]. Specifically, we will compare population growth between 2011 and 2016 (which comes from the 2016 Census - [[https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/prof/details/page.cfm?Lang=E&Geo1=CSD&Geo2=PR&Code2=01&Data=Count&SearchType=Begins&SearchPR=01&TABID=1&B1=All&Code1=3520005&SearchText=toronto][more info here]]). I've already cleaned and processed the dataset so it will play nice with QGIS. Both the raw and processed .csv files are in the data directory. 

*If you're going to use Excel or Calc, here are some steps to follow:*
- data setup http://www.qgis.nl/2012/07/13/koppelen-van-data-uit-csv-bestand/?lang=en
- cut the row you want and paste special into a new document. transpose the row into a column. 
- in order to get appropriate scale in later 3D model, concatenate a decimal and zero to cell and copy down the column (could also change the shapefile size parameters in qgis). 
- cut the column and paste special it
- (right click to) format first column and make sure it has leading zeroes to match the id values in the shapefile
- make sure you have a csvt and follow formula in current one https://anitagraser.com/2011/03/07/how-to-specify-data-types-of-csv-columns-for-use-in-qgis/

*in QGIS:*
- download the [[https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#a45bd45a-ede8-730e-1abc-93105b2c439f][neighbourhoods shapefile]] - you want the WGS84 coordinate system (I've included the files you need in the data directory)
- use ctrl-shift-v to add vector layer
- select the entire .zip that you downloaded
- import neighbourhood_pop.csv as a vector layer (not as a delimited one)
- join data from csv to existing shapefile https://gis.stackexchange.com/questions/182281/how-to-join-data-from-excel-to-an-attribute-table-in-qgis-without-creating-dupli
- save a new shapefile and edit column names if you wish

*in Blender:*
- Make sure you have the BlenderGIS plugin installed: https://github.com/domlysz/BlenderGIS
- set extrusion to the specific data column
- extrude along z axis
- if you want, separate the objects and create object names from the id field
- change coordinates to WGS84 latlon
- add a base or make the objects solid (use solidify modifier) if you want

*Here are some additional things you can do with pandas and numpy:* 

Import the data:
#+ipynb-newcell
#+BEGIN_SRC ipython
df = pd.read_csv('data/neighbourhood_pop.csv', dtype=str) # dtype str will keep the leading zeroes
df.head()
#+END_SRC
#+RESULTS:

Set index to ID:
#+ipynb-newcell
#+BEGIN_SRC ipython
df.set_index('id', inplace=True)
#+END_SRC
#+RESULTS:

Convert strings to floats in order to use numpy functions:
#+ipynb-newcell
#+BEGIN_SRC ipython
df['2011'] = df['2011'].astype(str).astype(float)
df['2016'] = df['2016'].astype(str).astype(float)
#+END_SRC
#+RESULTS:

Depending on the data you use, you might have to re-scale to make it printable. Consider the following image:

#+ipynb-newcell
#+BEGIN_SRC ipython
%%html
<img src="images/ladder2.gif"> 
#+END_SRC
#+RESULTS:

You can use numpy to convert to square root:
#+ipynb-newcell
#+BEGIN_SRC ipython
df['2016'] = np.sqrt(df['2016'])
df.head()
#+END_SRC
#+RESULTS:

Or logarithmic:
#+ipynb-newcell
#+BEGIN_SRC ipython
df['2011'] = np.log10(df['2011'])
#+END_SRC
#+RESULTS:

When you're done processing, you can output a new .csv for import into QGIS:
#+ipynb-newcell
#+BEGIN_SRC ipython
df.to_csv('data/neighbourhood_pop_scaled.csv')
#+END_SRC
#+RESULTS:
* Preparing to 3D Print
There are numerous software applications that you might use for preparing models prior to setting them up to print. You can likely do most of your prep in Blender, though, but the learning curve is steep. 
- Meshlab is not very user friendly, but has a million features built into it: http://www.meshlab.net/
- Meshmixer has been the go-to for a long time, and has everything from sculpting tools to 3D print prep: http://www.meshmixer.com/
- Cotangent is a new application from the guy who created Meshmixer. It has plenty of interesting features and is ideal for prepping 3D prints: https://www.cotangent.io/

Useful Blender shortcuts:
| keys     | function                                     |
|----------+----------------------------------------------|
| a        | select all                                   |
| c        | circle select                                |
| ctrl-lmb | lasso select                                 |
| b        | border select                                |
| ctrl-g   | group selected objects                       |
| m        | when object selected, move to specific layer |

Working with braille in Blender:
- installing braille https://blender.stackexchange.com/questions/39437/braille-text-in-blender
- go into the text editor stuff and find the font to load
- go into edit mode and extrude/bevel accordingly
* Printing Considerations
Some things to think about if you're preparing tactile models for blind users. 
- Braille is very challenging to print. If you're using an FDM printer, be careful that traces of filament are not being dragged across the dots. 
- Printing does not have to be static. Think about how to separate your models into individual, reconfigurable/modular chunks in order to create dynamic data representations. It is easy to 3D print lego-like connectors onto the faces of your objects. Additionally, attachable velcro tape gives you lots of options for creating modular graphics. 
